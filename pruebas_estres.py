import os
import sys
import time
import threading
import random
import statistics
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Tuple
import queue

# Agregar el directorio actual al path para importar m√≥dulos
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import chatbot
from logger_config import logger
from llm_pool import llm_pool

class EstressTester:
    def __init__(self, num_usuarios: int = 18, preguntas_por_usuario: int = 10, duracion_minutos: int = 10):
        self.num_usuarios = num_usuarios
        self.preguntas_por_usuario = preguntas_por_usuario
        self.duracion_minutos = duracion_minutos
        self.intervalo_preguntas = (duracion_minutos * 60) / preguntas_por_usuario  # segundos entre preguntas
        
        # M√©tricas
        self.metricas = {
            'tiempos_respuesta': [],
            'errores': [],
            'respuestas_exitosas': 0,
            'respuestas_fallidas': 0,
            'inicio_prueba': None,
            'fin_prueba': None,
            'usuarios_stats': {},
            'pool_stats_historia': []
        }
        
        # Lock para thread safety en m√©tricas
        self.metricas_lock = threading.Lock()
        
        # Preguntas de ejemplo para las pruebas
        self.preguntas_ejemplo = [
            "¬øCu√°les son las tarjetas disponibles en Colombia?",
            "¬øQu√© tipos de tarjetas de cr√©dito soporta Kushki?",
            "¬øCu√°les son los c√≥digos de respuesta para transacciones?",
            "¬øC√≥mo implementar pagos con tarjeta de d√©bito?",
            "¬øQu√© documentaci√≥n hay disponible para integraciones?",
            "¬øCu√°les son las comisiones para pagos internacionales?",
            "¬øC√≥mo configurar webhooks en Kushki?",
            "¬øQu√© m√©todos de pago est√°n disponibles en Ecuador?",
            "¬øCu√°l es el proceso para pagos recurrentes?",
            "¬øC√≥mo manejar errores en las transacciones?",
            "¬øQu√© es el 3DS y c√≥mo implementarlo?",
            "¬øCu√°les son los l√≠mites de transacci√≥n por pa√≠s?",
            "¬øC√≥mo funciona el sistema de tokens?",
            "¬øQu√© informaci√≥n necesito para integrar Kushki?",
            "¬øCu√°les son los ambientes de prueba disponibles?",
            "¬øC√≥mo implementar pagos m√≥viles?",
            "¬øQu√© tipos de reportes ofrece Kushki?",
            "¬øCu√°l es el proceso de certificaci√≥n?",
            "¬øC√≥mo manejar reembolsos en Kushki?",
            "¬øQu√© medidas de seguridad implementa Kushki?"
        ]

    def generar_user_id(self, numero_usuario: int) -> str:
        """Generar ID √∫nico para cada usuario de prueba"""
        return f"test_user_{numero_usuario:03d}"

    def obtener_pregunta_aleatoria(self) -> str:
        """Obtener una pregunta aleatoria para la prueba"""
        return random.choice(self.preguntas_ejemplo)

    def registrar_metrica(self, user_id: str, tiempo_respuesta: float, exito: bool, error: str = None):
        """Registrar m√©tricas de forma thread-safe"""
        with self.metricas_lock:
            self.metricas['tiempos_respuesta'].append(tiempo_respuesta)
            
            if exito:
                self.metricas['respuestas_exitosas'] += 1
            else:
                self.metricas['respuestas_fallidas'] += 1
                if error:
                    self.metricas['errores'].append({
                        'user_id': user_id,
                        'timestamp': datetime.now().isoformat(),
                        'error': error
                    })
            
            # Estad√≠sticas por usuario
            if user_id not in self.metricas['usuarios_stats']:
                self.metricas['usuarios_stats'][user_id] = {
                    'preguntas_realizadas': 0,
                    'tiempo_total': 0,
                    'errores': 0
                }
            
            self.metricas['usuarios_stats'][user_id]['preguntas_realizadas'] += 1
            self.metricas['usuarios_stats'][user_id]['tiempo_total'] += tiempo_respuesta
            
            if not exito:
                self.metricas['usuarios_stats'][user_id]['errores'] += 1

    def capturar_stats_pool(self):
        """Capturar estad√≠sticas del pool peri√≥dicamente"""
        while not hasattr(self, '_detener_stats'):
            try:
                stats = llm_pool.get_stats()
                timestamp = datetime.now().isoformat()
                
                with self.metricas_lock:
                    self.metricas['pool_stats_historia'].append({
                        'timestamp': timestamp,
                        'stats': stats
                    })
                
                time.sleep(5)  # Capturar cada 5 segundos
            except Exception as e:
                logger.error(f"Error capturando stats del pool: {e}")
                time.sleep(5)

    def simular_usuario(self, numero_usuario: int) -> Dict:
        """Simular las acciones de un usuario durante la prueba"""
        user_id = self.generar_user_id(numero_usuario)
        stats_usuario = {
            'user_id': user_id,
            'preguntas_completadas': 0,
            'tiempo_total': 0,
            'errores': 0,
            'inicio': datetime.now()
        }
        
        logger.info(f"üöÄ Iniciando simulaci√≥n para usuario {user_id}")
        
        # Inicializar historial para este usuario
        with chatbot.conversaciones_lock:
            chatbot.conversaciones[user_id] = []
        
        try:
            for pregunta_num in range(self.preguntas_por_usuario):
                inicio_pregunta = time.time()
                
                try:
                    # Obtener pregunta aleatoria
                    pregunta = self.obtener_pregunta_aleatoria()
                    
                    # Obtener historial actual de forma thread-safe
                    with chatbot.conversaciones_lock:
                        historial_actual = chatbot.conversaciones[user_id].copy()
                    
                    logger.info(f"üë§ {user_id} - Pregunta {pregunta_num + 1}/10: {pregunta[:50]}...")
                    
                    # Generar respuesta usando el sistema del chatbot
                    respuesta = chatbot.generar_respuesta(pregunta, historial_actual, user_id)
                    
                    tiempo_respuesta = time.time() - inicio_pregunta
                    
                    # Actualizar historial de forma thread-safe
                    with chatbot.conversaciones_lock:
                        chatbot.conversaciones[user_id].extend([
                            {"role": "user", "content": pregunta},
                            {"role": "assistant", "content": respuesta}
                        ])
                        chatbot.conversaciones[user_id] = chatbot.limitar_historial(chatbot.conversaciones[user_id])
                    
                    # Verificar si la respuesta indica error
                    es_error = any(error_phrase in respuesta.lower() for error_phrase in [
                        "temporalmente saturado", "error inesperado", "varios intentos"
                    ])
                    
                    # Registrar m√©tricas
                    self.registrar_metrica(user_id, tiempo_respuesta, not es_error, 
                                         respuesta if es_error else None)
                    
                    stats_usuario['preguntas_completadas'] += 1
                    stats_usuario['tiempo_total'] += tiempo_respuesta
                    
                    if es_error:
                        stats_usuario['errores'] += 1
                    
                    logger.info(f"‚úÖ {user_id} - Respuesta recibida en {tiempo_respuesta:.2f}s")
                    
                except Exception as e:
                    tiempo_respuesta = time.time() - inicio_pregunta
                    error_msg = str(e)
                    
                    logger.error(f"‚ùå {user_id} - Error en pregunta {pregunta_num + 1}: {error_msg}")
                    
                    self.registrar_metrica(user_id, tiempo_respuesta, False, error_msg)
                    stats_usuario['errores'] += 1
                
                # Esperar antes de la siguiente pregunta (excepto en la √∫ltima)
                if pregunta_num < self.preguntas_por_usuario - 1:
                    # Agregar variaci√≥n aleatoria del ¬±20% al intervalo
                    variacion = random.uniform(0.8, 1.2)
                    tiempo_espera = self.intervalo_preguntas * variacion
                    time.sleep(tiempo_espera)
        
        except Exception as e:
            logger.error(f"üí• Error cr√≠tico para usuario {user_id}: {e}")
        
        finally:
            # Limpiar memoria del usuario al finalizar
            chatbot.limpiar_memoria_usuario(user_id)
        
        stats_usuario['fin'] = datetime.now()
        stats_usuario['duracion_total'] = (stats_usuario['fin'] - stats_usuario['inicio']).total_seconds()
        
        logger.info(f"üèÅ Usuario {user_id} completado: {stats_usuario['preguntas_completadas']}/10 preguntas, {stats_usuario['errores']} errores")
        
        return stats_usuario

    def ejecutar_prueba(self) -> Dict:
        """Ejecutar la prueba de estr√©s completa"""
        logger.info("üß™ INICIANDO PRUEBA DE ESTR√âS")
        logger.info(f"üìä Configuraci√≥n: {self.num_usuarios} usuarios, {self.preguntas_por_usuario} preguntas c/u, {self.duracion_minutos} minutos")
        
        # Verificar que el sistema est√© listo
        self._verificar_sistema()
        
        self.metricas['inicio_prueba'] = datetime.now()
        
        # Iniciar captura de estad√≠sticas del pool
        stats_thread = threading.Thread(target=self.capturar_stats_pool, daemon=True)
        stats_thread.start()
        
        # Ejecutar usuarios concurrentes
        resultados_usuarios = []
        
        try:
            with ThreadPoolExecutor(max_workers=self.num_usuarios) as executor:
                # Enviar todos los usuarios de una vez
                futures = {
                    executor.submit(self.simular_usuario, i): i 
                    for i in range(1, self.num_usuarios + 1)
                }
                
                # Recoger resultados conforme van completando
                for future in as_completed(futures):
                    usuario_num = futures[future]
                    try:
                        resultado = future.result()
                        resultados_usuarios.append(resultado)
                        logger.info(f"‚úÖ Usuario {usuario_num} completado")
                    except Exception as e:
                        logger.error(f"‚ùå Usuario {usuario_num} fall√≥: {e}")
        
        except Exception as e:
            logger.error(f"üí• Error durante la ejecuci√≥n de la prueba: {e}")
        
        finally:
            # Detener captura de estad√≠sticas
            self._detener_stats = True
        
        self.metricas['fin_prueba'] = datetime.now()
        
        # Generar reporte final
        reporte = self._generar_reporte(resultados_usuarios)
        
        logger.info("üéâ PRUEBA DE ESTR√âS COMPLETADA")
        return reporte

    def _verificar_sistema(self):
        """Verificar que el sistema est√© listo para las pruebas"""
        logger.info("üîç Verificando sistema...")
        
        # Verificar pool de LLMs
        stats = llm_pool.get_stats()
        logger.info(f"üìä Pool LLM: {stats['available']}/{stats['pool_size']} disponibles")
        
        if stats['available'] == 0:
            raise Exception("No hay LLMs disponibles en el pool")
        
        # Verificar que los documentos est√©n cargados
        if not chatbot.system_prompt:
            logger.warning("‚ö†Ô∏è System prompt vac√≠o, cargando documentos...")
            chatbot.cargar_documentos()
        
        logger.info("‚úÖ Sistema verificado y listo")

    def _generar_reporte(self, resultados_usuarios: List[Dict]) -> Dict:
        """Generar reporte detallado de la prueba"""
        duracion_total = (self.metricas['fin_prueba'] - self.metricas['inicio_prueba']).total_seconds()
        
        reporte = {
            'resumen': {
                'usuarios_simulados': self.num_usuarios,
                'usuarios_completados': len(resultados_usuarios),
                'preguntas_por_usuario': self.preguntas_por_usuario,
                'duracion_total_segundos': duracion_total,
                'duracion_total_minutos': duracion_total / 60,
                'preguntas_totales_esperadas': self.num_usuarios * self.preguntas_por_usuario,
                'preguntas_exitosas': self.metricas['respuestas_exitosas'],
                'preguntas_fallidas': self.metricas['respuestas_fallidas'],
                'tasa_exito': (self.metricas['respuestas_exitosas'] / max(1, self.metricas['respuestas_exitosas'] + self.metricas['respuestas_fallidas'])) * 100
            },
            'rendimiento': {},
            'usuarios': resultados_usuarios,
            'errores': self.metricas['errores'],
            'pool_stats': self.metricas['pool_stats_historia']
        }
        
        # Estad√≠sticas de rendimiento
        if self.metricas['tiempos_respuesta']:
            tiempos = self.metricas['tiempos_respuesta']
            reporte['rendimiento'] = {
                'tiempo_respuesta_promedio': statistics.mean(tiempos),
                'tiempo_respuesta_mediana': statistics.median(tiempos),
                'tiempo_respuesta_min': min(tiempos),
                'tiempo_respuesta_max': max(tiempos),
                'tiempo_respuesta_std': statistics.stdev(tiempos) if len(tiempos) > 1 else 0,
                'throughput_preguntas_por_segundo': len(tiempos) / duracion_total if duracion_total > 0 else 0
            }
        
        return reporte

def imprimir_reporte(reporte: Dict):
    """Imprimir reporte de manera legible"""
    print("\n" + "="*60)
    print("üìä REPORTE DE PRUEBA DE ESTR√âS")
    print("="*60)
    
    resumen = reporte['resumen']
    print(f"\nüìà RESUMEN:")
    print(f"   üë• Usuarios simulados: {resumen['usuarios_simulados']}")
    print(f"   ‚úÖ Usuarios completados: {resumen['usuarios_completados']}")
    print(f"   ‚è±Ô∏è  Duraci√≥n total: {resumen['duracion_total_minutos']:.1f} minutos")
    print(f"   üìù Preguntas esperadas: {resumen['preguntas_totales_esperadas']}")
    print(f"   ‚úÖ Preguntas exitosas: {resumen['preguntas_exitosas']}")
    print(f"   ‚ùå Preguntas fallidas: {resumen['preguntas_fallidas']}")
    print(f"   üìä Tasa de √©xito: {resumen['tasa_exito']:.1f}%")
    
    if 'rendimiento' in reporte and reporte['rendimiento']:
        perf = reporte['rendimiento']
        print(f"\n‚ö° RENDIMIENTO:")
        print(f"   üìä Tiempo promedio: {perf['tiempo_respuesta_promedio']:.2f}s")
        print(f"   üìä Tiempo mediana: {perf['tiempo_respuesta_mediana']:.2f}s")
        print(f"   üìä Tiempo m√≠nimo: {perf['tiempo_respuesta_min']:.2f}s")
        print(f"   üìä Tiempo m√°ximo: {perf['tiempo_respuesta_max']:.2f}s")
        print(f"   üìä Desviaci√≥n est√°ndar: {perf['tiempo_respuesta_std']:.2f}s")
        print(f"   üöÄ Throughput: {perf['throughput_preguntas_por_segundo']:.2f} preguntas/segundo")
    
    if reporte['errores']:
        print(f"\n‚ùå ERRORES ({len(reporte['errores'])}):")
        for error in reporte['errores'][:5]:  # Mostrar solo los primeros 5
            print(f"   ‚Ä¢ {error['user_id']}: {error['error'][:100]}...")
        if len(reporte['errores']) > 5:
            print(f"   ... y {len(reporte['errores']) - 5} errores m√°s")
    
    print("\n" + "="*60)

def main():
    """Funci√≥n principal para ejecutar las pruebas"""
    print("üß™ INICIANDO PRUEBAS DE ESTR√âS PARA CHASKI BOT")
    print("="*50)
    
    try:
        # Configuraci√≥n de la prueba
        tester = EstressTester(
            num_usuarios=18,
            preguntas_por_usuario=10,
            duracion_minutos=10
        )
        
        # Ejecutar prueba
        reporte = tester.ejecutar_prueba()
        
        # Mostrar resultados
        imprimir_reporte(reporte)
        
        # Guardar reporte en archivo
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"reporte_estres_{timestamp}.txt"
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("REPORTE DE PRUEBA DE ESTR√âS - CHASKI BOT\n")
            f.write("="*50 + "\n\n")
            f.write(f"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            import json
            f.write(json.dumps(reporte, indent=2, ensure_ascii=False, default=str))
        
        print(f"\nüíæ Reporte detallado guardado en: {filename}")
        
    except KeyboardInterrupt:
        print("\nüõë Prueba interrumpida por el usuario")
    except Exception as e:
        print(f"\nüí• Error durante las pruebas: {e}")
        logger.error(f"Error en pruebas de estr√©s: {e}")

if __name__ == "__main__":
    main() 